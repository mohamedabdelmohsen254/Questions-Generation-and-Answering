{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install git+https://github.com/boudinfl/pke.git\n# !pip install matplotlib\n# !python -m spacy download en_core_web_sm\n# !pip install --user scipy==1.8.1\n# !pip install transformers\n\n# # !pip install keybert\n# # !pip install keybert[flair]\n# # !pip install keybert[gensim]\n# # !pip install keybert[spacy]\n# # !pip install keybert[use]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T06:09:07.267989Z","iopub.execute_input":"2023-01-26T06:09:07.268404Z","iopub.status.idle":"2023-01-26T06:09:07.274136Z","shell.execute_reply.started":"2023-01-26T06:09:07.268369Z","shell.execute_reply":"2023-01-26T06:09:07.272533Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"import collections\nfrom collections import Counter\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport string\nimport re\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize\n\nimport pke\n\nstop_words = stopwords.words('english')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-26T09:44:41.424277Z","iopub.execute_input":"2023-01-26T09:44:41.424739Z","iopub.status.idle":"2023-01-26T09:44:41.442914Z","shell.execute_reply.started":"2023-01-26T09:44:41.424701Z","shell.execute_reply":"2023-01-26T09:44:41.435579Z"},"trusted":true},"execution_count":604,"outputs":[]},{"cell_type":"code","source":"context= \"\"\"\ndeep learning also known as deep structured learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning . learning can be supervised , semi-supervised or unsupervised . deep-learning architectures such as deep neural networks , deep belief networks , deep reinforcement learning , recurrent neural networks , convolutional neural networks and transformers have been applied to fields including computer vision , speech recognition , natural language processing , machine translation , bioinformatics , drug design , medical image analysis , climate science , material inspection and board game programs , where they have produced results comparable to and in some cases surpassing human expert performance . artificial neural networks anns were inspired by information processing and distributed communication nodes in biological systems . anns have various differences from biological brains . specifically , artificial neural networks tend to be static and symbolic , while the biological brain of most living organisms is dynamic plastic and analogue . the adjective deep in deep learning refers to the use of multiple layers in the network . early work showed that a linear perceptron can not be a universal classifier , but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can . deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size , which permits practical application and optimized implementation , while retaining theoretical universality under mild conditions . in deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models , for the sake of efficiency , trainability and understandability , hence the structured part . python is a high-level , general-purpose programming language . its design philosophy emphasizes code readability with the use of significant indentation . python is dynamically-typed and garbage-collected . it supports multiple programming paradigms , including structured particularly procedural , object-oriented and functional programming . it is often described as a batteries included language due to its comprehensive standard library . guido van rossum began working on python in the late s as a successor to the abc programming language and first released it in as python ... python . was released in and introduced new features such as list comprehensions , cycle-detecting garbage collection , reference counting , and unicode support . python . , released in , was a major revision that is not completely backward-compatible with earlier versions . python was discontinued with version .. in . python consistently ranks as one of the most popular programming languages . machine learning ml is a field of inquiry devoted to understanding and building methods that learn , that is , methods that leverage data to improve performance on some set of tasks . it is seen as a part of artificial intelligence . machine learning algorithms build a model based on sample data , known as training data , in order to make predictions or decisions without being explicitly programmed to do so . machine learning algorithms are used in a wide variety of applications , such as in medicine , email filtering , speech recognition , and computer vision , where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks . a subset of machine learning is closely related to computational statistics , which focuses on making predictions using computers , but not all machine learning is statistical learning . the study of mathematical optimization delivers methods , theory and application domains to the field of machine learning . data mining is a related field of study , focusing on exploratory data analysis through unsupervised learning . some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain . in its application across business problems , machine learning is also referred to as predictive analytics . mohamed salah hamed mahrous ghaly egyptian arabic pronunciation born june is an egyptian professional footballer who plays as a forward for premier league club liverpool and captains the egypt national team . considered one of the best players in the world and amongst the greatest african players of all time , he is known for his finishing , dribbling , and speed . salah started his senior career in playing for al mokawloon , departing in to join basel , where he won two swiss super league titles . in , salah joined chelsea for a reported fee of million , but limited gametime led to successive loans to fiorentina and roma , who later signed him permanently for million . in the season , salah was a key figure in romas title race against ultimate league winners juventus , reaching double figures in both goals and assists . in , salah signed for liverpool for a then-club record transfer of . million . in his first season , he set the record for most premier league goals scored in a -game season and helped liverpool to the uefa champions league final . salah went on to be an integral player in the clubs champions league and premier league title successes the following two seasons , and has since also won the fa cup and the league cup . salah has achieved numerous individual accolades , including two pfa players player of the year awards , three premier league golden boots , the premier league player of the season , the premier league playmaker of the season , and finished third for the best fifa mens player in and . he received the fifa pusks award for his winning strike in the first merseyside derby of the season . at international level , salah represented egypt at youth level before making his senior debut in . following his performances at the summer olympics , he was named caf most promising african talent of the year . since then , he finished as runner-up in the and africa cup of nations and was top scorer during caf qualification as egypt qualified for the fifa world cup . salah was named caf african footballer of the year and , bbc african footballer of the year and , and was selected in the africa cup of nations team of the tournament , africa cup of nations team of the tournament and the caf team of the year on several occasions .\n      \"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-01-26T09:36:04.541105Z","iopub.execute_input":"2023-01-26T09:36:04.541458Z","iopub.status.idle":"2023-01-26T09:36:04.550009Z","shell.execute_reply.started":"2023-01-26T09:36:04.541427Z","shell.execute_reply":"2023-01-26T09:36:04.548935Z"},"trusted":true},"execution_count":596,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"* This code defines several functions that are used to clean and normalize a given text.\n\n* remove_non_ascii(text) : removes non-ASCII characters from a list of tokenized words.\n \n* remove_stop_words(text) : removes stop words from the text.\n \n* Removing_numbers(text) : removes numbers from the text\n \n* lower_case(text) : converts all characters of the text to lowercase.\n\n* Removing_punctuations(text) : removes punctuations from the text.\n \n* remove_emails(text) : removes email addresses from the text.\n \n* Removing_urls(text) : removes URLs from the text.\n \n* normalized_sentence(sentence) : takes in a sentence and applies all the above defined functions on it in a particular order to return a cleaned and normalized sentence.","metadata":{}},{"cell_type":"code","source":"def remove_non_ascii(text):\n    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n    return text.encode('ascii','ignore').decode()\n\ndef remove_stop_words(text):\n\n    Text=[i for i in str(text).split() if i not in stop_words]\n    return \" \".join(Text)\n\ndef Removing_numbers(text):\n    text=''.join([i for i in text if not i.isdigit()])\n    return text\n\ndef lower_case(text):\n    \n    text = text.split()\n\n    text=[y.lower() for y in text]\n    \n    return \" \" .join(text)\n\ndef Removing_punctuations(text):\n    ## Remove punctuations\n    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n    text = text.replace('؛',\"\", )\n    \n    return text\n\ndef remove_emails(text):\n    return re.sub(r'[A-Za-z0-9]*@[A-Za-z]*\\.?[A-Za-z0-9]*', \"\", text)\n    \ndef Removing_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\n\n\n            \n\ndef normalized_sentence(sentence):\n    sentence = remove_non_ascii(sentence)\n    sentence = remove_emails(sentence)\n    sentence = lower_case(sentence)\n    sentence = remove_stop_words(sentence)\n    sentence = Removing_numbers(sentence)\n    sentence = Removing_punctuations(sentence)\n    sentence = Removing_urls(sentence)\n    #sentence = lemmatization(sentence)\n    return sentence\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-26T09:30:10.567278Z","iopub.execute_input":"2023-01-26T09:30:10.567676Z","iopub.status.idle":"2023-01-26T09:30:10.579349Z","shell.execute_reply.started":"2023-01-26T09:30:10.567645Z","shell.execute_reply":"2023-01-26T09:30:10.578274Z"},"trusted":true},"execution_count":581,"outputs":[]},{"cell_type":"code","source":"context = normalized_sentence(context)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T08:30:16.484231Z","iopub.execute_input":"2023-01-26T08:30:16.484613Z","iopub.status.idle":"2023-01-26T08:30:16.494071Z","shell.execute_reply.started":"2023-01-26T08:30:16.484583Z","shell.execute_reply":"2023-01-26T08:30:16.492935Z"},"trusted":true},"execution_count":539,"outputs":[]},{"cell_type":"markdown","source":"# Keyword extraction","metadata":{}},{"cell_type":"markdown","source":"Keyword extraction is an important step in question answering systems because it helps the system understand the main topic and focus of the question. By identifying the keywords in a question, the system can use them to search for relevant information and retrieve the most relevant answer. Additionally, keyword extraction can also help to improve the efficiency of the question answering system by reducing the amount of irrelevant information that needs to be processed. Overall, keyword extraction helps to ensure that the system is able to understand and respond to the user's question accurately and efficiently.","metadata":{}},{"cell_type":"code","source":"def topicRank(text):\n    # initialize keyphrase extraction model, here TopicRank\n    extractor = pke.unsupervised.TopicRank()\n\n    # load the content of the document, here document is expected to be in raw\n    # format (i.e. a simple text file) and preprocessing is carried out using spacy\n    extractor.load_document(input=text, language='en')\n\n    # keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n    # and adjectives (i.e. `(Noun|Adj)*`)\n    extractor.candidate_selection()\n\n    # candidate weighting, in the case of TopicRank: using a random walk algorithm\n    extractor.candidate_weighting()\n\n    # N-best selection, keyphrases contains the 10 highest scored candidates as\n    # (keyphrase, score) tuples\n    keyphrases = extractor.get_n_best(n=10)\n    return [a_tuple[0] for a_tuple in keyphrases]\n\ndef TfIdf(text):\n    # initialize keyphrase extraction model, here TfIdf\n    extractor = pke.unsupervised.TfIdf()\n\n    # load the content of the document, here document is expected to be in raw\n    # format (i.e. a simple text file) and preprocessing is carried out using spacy\n    extractor.load_document(input=text, language='en' )\n\n    # keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n    # and adjectives (i.e. `(Noun|Adj)*`)\n    extractor.candidate_selection()\n\n    # candidate weighting, in the case of TopicRank: using a random walk algorithm\n    extractor.candidate_weighting()\n\n    # N-best selection, keyphrases contains the 10 highest scored candidates as\n    # (keyphrase, score) tuples\n    keyphrases = extractor.get_n_best(n=10)\n    return [a_tuple[0] for a_tuple in keyphrases]\ndef yake(text):\n    # initialize keyphrase extraction model, here TopicRank\n    extractor = pke.unsupervised.YAKE()\n\n    # load the content of the document, here document is expected to be in raw\n    # format (i.e. a simple text file) and preprocessing is carried out using spacy\n    extractor.load_document(input=text, language='en')\n\n    # keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n    # and adjectives (i.e. `(Noun|Adj)*`)\n    extractor.candidate_selection()\n\n    # candidate weighting, in the case of TopicRank: using a random walk algorithm\n    extractor.candidate_weighting()\n\n    # N-best selection, keyphrases contains the 10 highest scored candidates as\n    # (keyphrase, score) tuples\n    keyphrases = extractor.get_n_best(n=10)\n    return [a_tuple[0] for a_tuple in keyphrases]\n\ndef multipartiteRank(text):\n    # initialize keyphrase extraction model, here TopicRank\n    extractor = pke.unsupervised.MultipartiteRank()\n\n    # load the content of the document, here document is expected to be in raw\n    # format (i.e. a simple text file) and preprocessing is carried out using spacy\n    extractor.load_document(input=text, language='en')\n\n    # keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n    # and adjectives (i.e. `(Noun|Adj)*`)\n    extractor.candidate_selection()\n\n    # candidate weighting, in the case of TopicRank: using a random walk algorithm\n    extractor.candidate_weighting()\n\n    # N-best selection, keyphrases contains the 10 highest scored candidates as\n    # (keyphrase, score) tuples\n    keyphrases = extractor.get_n_best(n=10)\n    return [a_tuple[0] for a_tuple in keyphrases]\ndef GetKeywords(text):\n    yakeKeyWords = yake(text)\n    topicRankKeyWords = topicRank(text)\n    multipartiteRankKeyWords = multipartiteRank(text)\n    tfidfKeyWords = TfIdf(text)\n    filteredKeys = yakeKeyWords + topicRankKeyWords + multipartiteRankKeyWords + tfidfKeyWords\n    #print([item for item, count in collections.Counter(filteredKeys).items() if count >= 3])\n\n    return [item for item, count in collections.Counter(filteredKeys).items() if count >= 2]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T08:38:56.868814Z","iopub.execute_input":"2023-01-26T08:38:56.869205Z","iopub.status.idle":"2023-01-26T08:38:56.882127Z","shell.execute_reply.started":"2023-01-26T08:38:56.869173Z","shell.execute_reply":"2023-01-26T08:38:56.880683Z"},"trusted":true},"execution_count":553,"outputs":[]},{"cell_type":"code","source":"#generate the intersection of all the keywords generated\nkeywords=GetKeywords(context)\nkeywords","metadata":{"execution":{"iopub.status.busy":"2023-01-26T08:38:58.591072Z","iopub.execute_input":"2023-01-26T08:38:58.591451Z","iopub.status.idle":"2023-01-26T08:39:09.845886Z","shell.execute_reply.started":"2023-01-26T08:38:58.591406Z","shell.execute_reply":"2023-01-26T08:39:09.844815Z"},"trusted":true},"execution_count":554,"outputs":[{"execution_count":554,"output_type":"execute_result","data":{"text/plain":"['neural networks',\n 'artificial neural networks',\n 'deep',\n 'league',\n 'deep learning',\n 'neural',\n 'machine learning methods',\n 'salah',\n 'python',\n 'data',\n 'natural language processing',\n 'premier league club liverpool',\n 'season']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Question Generation","metadata":{}},{"cell_type":"markdown","source":"## T5 base","metadata":{}},{"cell_type":"markdown","source":"T5 (Text-to-Text Transfer Transformer) is a transformer-based neural network model developed by Google Research for a wide range of natural language processing tasks. T5 is an extension of the transformer architecture, which was introduced in the original transformer model (BERT) and has since been used in many other models.\n\nOne of the main innovations of T5 is its text-to-text transfer learning approach, which allows the model to be fine-tuned for a wide range of natural language processing tasks using a single pre-trained model. This is achieved by training T5 on a large corpus of diverse text using a task-agnostic training objective, which encourages the model to learn general language understanding.","metadata":{}},{"cell_type":"markdown","source":"This pre-trained model, mrm8488/t5-base-finetuned-question-generation-ap is fine-tuned on the question generation task, using the T5 transformer model architecture. It is trained to generate questions based on the given answer and context. With this tokenizer and model instance, ","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelWithLMHead, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\nmodel = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n","metadata":{"execution":{"iopub.status.busy":"2023-01-26T06:42:11.328083Z","iopub.status.idle":"2023-01-26T06:42:11.328953Z","shell.execute_reply.started":"2023-01-26T06:42:11.328672Z","shell.execute_reply":"2023-01-26T06:42:11.328697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This code defines a function called get_question() which takes 3 parameters as inputs:**\n* **answer**: a string representing the answer to a question\n* **context**: a string representing the context or background information related to the answer\n* **max_length**: an optional parameter that defaults to 64, which represents the maximum length of the generated question.\n\nThe function first concatenates the answer and context strings with a separator \" \" and saves the result in the input_text variable. This creates a single string that contains both the answer and the context, which is needed as the input for the language model.\n\nNext, the function uses the tokenizer that was loaded earlier to tokenize the input text. The tokenizer takes the input text as a list of strings and returns a dictionary containing the tokenized input ids, attention mask, and other features. The input_text is passed in the form of a list to the tokenizer. The tokenizer tokenizes the input_text and returns a dictionary containing the tokenized input ids, attention mask, and other features. The return_tensors='pt' flag indicates that the tokenizer should return PyTorch tensors.\n\nThen, the function uses the loaded model to generate a question based on the tokenized input. The generate() method of the model is used for this purpose. The method takes the tokenized input, attention mask and maximum length of the generated question as input. The input_ids and attention_mask are obtained from the features dictionary returned by the tokenizer.\n\nFinally, the function uses the tokenizer to decode the output and return the generated question. The decode() method of the tokenizer is used for this purpose. The method takes the tokenized output and returns the decoded text. The skip_special_tokens flag is set to True to remove any special tokens that may have been added during the tokenization process.","metadata":{}},{"cell_type":"code","source":"def get_question(answer, context, max_length=64):\n    # Concatenate answer and context strings with a separator \"  \"\n    input_text = \"answer: %s  context: %s \" % (answer, context)\n    \n    # Tokenize the input text and return a dictionary of features\n    features = tokenizer([input_text], return_tensors='pt')\n\n    # Use the loaded model to generate a question based on the tokenized input\n    output = model.generate(input_ids=features['input_ids'], \n               attention_mask=features['attention_mask'],\n               max_length=max_length)\n\n    # Decode the tokenized output and return the generated question\n    return tokenizer.decode(output[0],skip_special_tokens=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-26T09:16:23.005602Z","iopub.execute_input":"2023-01-26T09:16:23.006010Z","iopub.status.idle":"2023-01-26T09:16:23.012467Z","shell.execute_reply.started":"2023-01-26T09:16:23.005975Z","shell.execute_reply":"2023-01-26T09:16:23.011279Z"},"trusted":true},"execution_count":579,"outputs":[]},{"cell_type":"code","source":"ques=[]\n#iterating over the list of keywords\nfor i in range(len(keywords)):\n    # generating a question for each keyword by passing it and the context\n    question=get_question(keywords[i],context)\n    #appending each question to the list 'ques'\n    ques.append(question)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-26T08:39:44.838729Z","iopub.execute_input":"2023-01-26T08:39:44.839462Z","iopub.status.idle":"2023-01-26T08:41:44.771094Z","shell.execute_reply.started":"2023-01-26T08:39:44.839423Z","shell.execute_reply":"2023-01-26T08:41:44.770005Z"},"trusted":true},"execution_count":556,"outputs":[]},{"cell_type":"code","source":"#print the generated questions with it's answers\nfor i in range(len(ques)):\n    print(\"\\033[1m\"+ques[i]+\"\\033[0m\" +\"\\n\" + keywords[i])","metadata":{"execution":{"iopub.status.busy":"2023-01-26T08:41:44.773493Z","iopub.execute_input":"2023-01-26T08:41:44.773880Z","iopub.status.idle":"2023-01-26T08:41:44.780159Z","shell.execute_reply.started":"2023-01-26T08:41:44.773825Z","shell.execute_reply":"2023-01-26T08:41:44.779130Z"},"trusted":true},"execution_count":557,"outputs":[{"name":"stdout","text":"\u001b[1mquestion: What type of network is used in deep learning?\u001b[0m\nneural networks\n\u001b[1mquestion: What type of network is deep structured learning based on?\u001b[0m\nartificial neural networks\n\u001b[1mquestion: What is the modern variation of deep learning?\u001b[0m\ndeep\n\u001b[1mquestion: What league did salah win the premier league golden boot?\u001b[0m\nleague\n\u001b[1mquestion: What is a modern variation of machine learning?\u001b[0m\ndeep learning\n\u001b[1mquestion: What type of network is deep structured learning based on?\u001b[0m\nneural\n\u001b[1mquestion: What is a broader family of?\u001b[0m\nmachine learning methods\n\u001b[1mquestion: Who was named caf african footballer of the year?\u001b[0m\nsalah\n\u001b[1mquestion: What was the name of the programming language that was discontinued in the late s?\u001b[0m\npython\n\u001b[1mquestion: What does deep learning use to improve performance?\u001b[0m\ndata\n\u001b[1mquestion: What is one field where deep learning has been applied?\u001b[0m\nnatural language processing\n\u001b[1mquestion: What club did mohamed salah play for?\u001b[0m\npremier league club liverpool\n\u001b[1mquestion: What was salah's first season in the premier league?\u001b[0m\nseason\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After generating the questions we may need to get better answers instead of the keywords so, I will use a Question Answering model","metadata":{}},{"cell_type":"markdown","source":"# Question Answering\n\nA QA model is trained to answer natural language questions by understanding and interpreting the question, and then selecting the most appropriate answer from a given context. This can help to ensure that the generated question is relevant and makes sense, and that the answer to the question is accurate.","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nquestion_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n\nfor i in range(len(ques)):\n    print(\"\\033[1m\"+ques[i]+\"\\033[0m\" +\"\\n\" )\n    result = question_answerer(question=ques[i],     context=context)\n    print(result['answer'])","metadata":{"execution":{"iopub.status.busy":"2023-01-26T08:43:47.041844Z","iopub.execute_input":"2023-01-26T08:43:47.042520Z","iopub.status.idle":"2023-01-26T08:44:12.794921Z","shell.execute_reply.started":"2023-01-26T08:43:47.042475Z","shell.execute_reply":"2023-01-26T08:44:12.793675Z"},"trusted":true},"execution_count":558,"outputs":[{"name":"stdout","text":"\u001b[1mquestion: What type of network is used in deep learning?\u001b[0m\n\nneural networks\n\u001b[1mquestion: What type of network is deep structured learning based on?\u001b[0m\n\nartificial neural networks\n\u001b[1mquestion: What is the modern variation of deep learning?\u001b[0m\n\npredictive analytics\n\u001b[1mquestion: What league did salah win the premier league golden boot?\u001b[0m\n\nthe premier league player of the season\n\u001b[1mquestion: What is a modern variation of machine learning?\u001b[0m\n\npredictive analytics\n\u001b[1mquestion: What type of network is deep structured learning based on?\u001b[0m\n\nartificial neural networks\n\u001b[1mquestion: What is a broader family of?\u001b[0m\n\nmachine learning algorithms\n\u001b[1mquestion: Who was named caf african footballer of the year?\u001b[0m\n\nsalah\n\u001b[1mquestion: What was the name of the programming language that was discontinued in the late s?\u001b[0m\n\npython\n\u001b[1mquestion: What does deep learning use to improve performance?\u001b[0m\n\ndata and neural networks\n\u001b[1mquestion: What is one field where deep learning has been applied?\u001b[0m\n\ncomputer vision\n\u001b[1mquestion: What club did mohamed salah play for?\u001b[0m\n\nliverpool\n\u001b[1mquestion: What was salah's first season in the premier league?\u001b[0m\n\nhe set the record for most premier league goals scored in a -game season\n","output_type":"stream"}]}]}