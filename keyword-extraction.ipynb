{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/boudinfl/pke.git\n!pip install matplotlib\n!python -m spacy download en_core_web_sm\n!pip install --user scipy==1.8.1\n# !pip install keybert\n# !pip install keybert[flair]\n# !pip install keybert[gensim]\n# !pip install keybert[spacy]\n# !pip install keybert[use]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T04:59:45.284846Z","iopub.execute_input":"2023-01-26T04:59:45.285998Z","iopub.status.idle":"2023-01-26T05:00:37.873576Z","shell.execute_reply.started":"2023-01-26T04:59:45.285957Z","shell.execute_reply":"2023-01-26T05:00:37.872228Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/boudinfl/pke.git\n  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-swkq5j5p\n  Running command git clone --filter=blob:none --quiet https://github.com/boudinfl/pke.git /tmp/pip-req-build-swkq5j5p\n  Resolved https://github.com/boudinfl/pke.git to commit 8f1d05dcc52041c9920ba0f9d5231fe6086d12c4\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from pke==2.0.0) (3.8.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from pke==2.0.0) (2.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pke==2.0.0) (1.21.6)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from pke==2.0.0) (1.7.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from pke==2.0.0) (1.0.2)\nRequirement already satisfied: unidecode in /opt/conda/lib/python3.7/site-packages (from pke==2.0.0) (1.3.4)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pke==2.0.0) (0.18.2)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from pke==2.0.0) (1.0.1)\nRequirement already satisfied: spacy>=3.2.3 in /opt/conda/lib/python3.7/site-packages (from pke==2.0.0) (3.3.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (6.3.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.8)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.11)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.4)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.5)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.9)\nRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (4.1.1)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.10.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (4.64.0)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.4.2)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.7.9)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.10.1)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (8.0.17)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (59.8.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (23.0)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.28.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.8.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->pke==2.0.0) (5.1.1)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->pke==2.0.0) (2021.11.10)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->pke==2.0.0) (8.1.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pke==2.0.0) (3.1.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.3->pke==2.0.0) (3.8.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.26.14)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk->pke==2.0.0) (6.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.2)\nBuilding wheels for collected packages: pke\n  Building wheel for pke (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pke: filename=pke-2.0.0-py3-none-any.whl size=6160287 sha256=cd7137d9b04ea8979f0760e748a614e65c8bbbc4620fd7a8b1b413bbdd5c4878\n  Stored in directory: /tmp/pip-ephem-wheel-cache-tfxnaqbw/wheels/fa/b3/09/612ee93bf3ee4164bcd5783e742942cdfc892a86039d3e0a33\nSuccessfully built pke\nInstalling collected packages: pke\nSuccessfully installed pke-2.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.5.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (4.33.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.21.6)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (23.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.4.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (9.1.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting en-core-web-sm==3.3.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.3.0) (3.3.2)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\nRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.1)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.3.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (23.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.11)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.8)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.9)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.4)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.9)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.8)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (59.8.0)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.5)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[31mERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12; 1.9.2 Requires-Python >=3.8; 1.9.3 Requires-Python >=3.8\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scipy==1.8.1 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.6.2, 1.6.3, 1.7.0rc1, 1.7.0rc2, 1.7.0, 1.7.1, 1.7.2, 1.7.3)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for scipy==1.8.1\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom collections import Counter\nimport re\nimport string\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\nimport pke\nimport collections\n\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('omw-1.4')\nnltk.download('punkt')\nnltk.download('stopwords')\n\nstop_words = stopwords.words('english')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-26T05:02:08.157071Z","iopub.execute_input":"2023-01-26T05:02:08.157908Z","iopub.status.idle":"2023-01-26T05:02:08.217001Z","shell.execute_reply.started":"2023-01-26T05:02:08.157841Z","shell.execute_reply":"2023-01-26T05:02:08.215775Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('/kaggle/input/content-for-mcq/Content for mcq .txt' ,'r') as f:\n    context=f.read()\nprint (context)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:08.399702Z","iopub.execute_input":"2023-01-26T05:02:08.400094Z","iopub.status.idle":"2023-01-26T05:02:08.411487Z","shell.execute_reply.started":"2023-01-26T05:02:08.400059Z","shell.execute_reply":"2023-01-26T05:02:08.410198Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\nOptimization answers the question: How do we do things better? What is the best decision for a complex problem?\n\nExample: Given business priorities, resource constraints and available technology, determine the best way to optimize your IT platform to satisfy the needs of every user.\n\nOptimization supports innovation. It takes your resources and needs into consideration and helps you find the best possible way to accomplish your goals.\n\nPredictive Modeling answers the questions: What will happen next?  How will it affect my business?\n\nExample: Hotels and casinos can predict which VIP customers will be more interested in particular vacation packages.\n\nIf you have 10 million customers and want to do a marketing campaign, who's most likely to respond? How do you segment that group? And how do you determine who's most likely to leave your organization? Predictive modeling provides the answers.\n\nForecasting answers the questions: What if these trends continue? How much is needed? When will it be needed?\n\nExample: Retailers can predict how demand for individual products will vary from store to store.\n\nForecasting is one of the hottest markets – and hottest analytical applications – right now. It applies everywhere. In particular, forecasting demand helps supply just enough inventory, so you don’t run out or have too much. \n\nStatistical Analysis answers the questions: Why is this happening? What opportunities am I missing?\n\nExample: Banks can discover why an increasing number of customers are refinancing their homes. \n\nHere we can begin to run some complex analytics, like frequency models and regression analysis. We can begin to look at why things are happening using the stored data and then begin to answer questions based on the data.\n\nAlerts answer the questions: When should I react? What actions are needed now?\n\nExample: Sales executives receive alerts when sales targets are falling behind. \n\nWith alerts, you can learn when you have a problem and be notified when something similar happens again in the future. Alerts can appear via e-mail, RSS feeds or as red dials on a scorecard or dashboard. \n\nQuery Drilldown (or OLAP) answers the questions: Where exactly is the problem? How do I find the answers?\n\nExample: Sort and explore data about different types of cell phone users and their calling behaviors.\n\nQuery drilldown allows for a little bit of discovery. OLAP lets you manipulate the data yourself to find out how many, what color and where.\n\nAd Hoc Reports answer the questions: How many? How often? Where?\n\nExample: Custom reports that describe the number of hospital patients for every diagnosis code for each day of the week. \n\nAt their best, ad hoc reports let you ask the questions and request a couple of custom reports to find the answers.\n\nStandard Reports answer the questions: What happened? When did it happen?\n\nExample: Monthly or quarterly financial reports. \n\nWe all know about these. They're generated on a regular basis and describe just \"what happened\" in a particular area. They're useful to some extent, but not for making long-term decisions.\n","output_type":"stream"}]},{"cell_type":"code","source":"Keywords = ['Optimization','Ad Hoc Reports','Standard Reports','Query Drilldown','OLAP','Alerts',\n           'Forecasting','Predictive Modeling']","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:08.615996Z","iopub.execute_input":"2023-01-26T05:02:08.618157Z","iopub.status.idle":"2023-01-26T05:02:08.622912Z","shell.execute_reply.started":"2023-01-26T05:02:08.618116Z","shell.execute_reply":"2023-01-26T05:02:08.621905Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def remove_non_ascii(text):\n    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n    return text.encode('ascii','ignore').decode()\n\ndef remove_stop_words(text):\n\n    Text=[i for i in str(text).split() if i not in stop_words]\n    return \" \".join(Text)\n\ndef Removing_numbers(text):\n    text=''.join([i for i in text if not i.isdigit()])\n    return text\n\ndef lower_case(text):\n    \n    text = text.split()\n\n    text=[y.lower() for y in text]\n    \n    return \" \" .join(text)\n\ndef Removing_punctuations(text):\n    ## Remove punctuations\n    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n    text = text.replace('؛',\"\", )\n    \n    ## remove extra whitespace\n    text = re.sub('\\s+', ' ', text)\n    text =  \" \".join(text.split())\n    return text.strip()\n\ndef remove_emails(text):\n    return re.sub(r'[A-Za-z0-9]*@[A-Za-z]*\\.?[A-Za-z0-9]*', \"\", text)\n    \ndef Removing_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\n\n\n            \n\ndef normalized_sentence(sentence):\n    sentence = remove_non_ascii(sentence)\n    sentence = remove_emails(sentence)\n    sentence = lower_case(sentence)\n    sentence = remove_stop_words(sentence)\n    sentence = Removing_numbers(sentence)\n    sentence = Removing_punctuations(sentence)\n    sentence = Removing_urls(sentence)\n    #sentence = lemmatization(sentence)\n    return sentence\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:08.759380Z","iopub.execute_input":"2023-01-26T05:02:08.759742Z","iopub.status.idle":"2023-01-26T05:02:08.771824Z","shell.execute_reply.started":"2023-01-26T05:02:08.759699Z","shell.execute_reply":"2023-01-26T05:02:08.770736Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"cleaned_context = normalized_sentence(context)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:08.932015Z","iopub.execute_input":"2023-01-26T05:02:08.934004Z","iopub.status.idle":"2023-01-26T05:02:08.941134Z","shell.execute_reply.started":"2023-01-26T05:02:08.933972Z","shell.execute_reply":"2023-01-26T05:02:08.940036Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"cleaned_context","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:09.112983Z","iopub.execute_input":"2023-01-26T05:02:09.113272Z","iopub.status.idle":"2023-01-26T05:02:09.122042Z","shell.execute_reply.started":"2023-01-26T05:02:09.113246Z","shell.execute_reply":"2023-01-26T05:02:09.120924Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'optimization answers question things better best decision complex problem example given business priorities resource constraints available technology determine best way optimize platform satisfy needs every user optimization supports innovation takes resources needs consideration helps find best possible way accomplish goals predictive modeling answers questions happen next affect business example hotels casinos predict vip customers interested particular vacation packages million customers want marketing campaign who s likely respond segment group determine who s likely leave organization predictive modeling provides answers forecasting answers questions trends continue much needed needed example retailers predict demand individual products vary store store forecasting one hottest markets hottest analytical applications right now applies everywhere particular forecasting demand helps supply enough inventory dont run much statistical analysis answers questions happening opportunities missing example banks discover increasing number customers refinancing homes begin run complex analytics like frequency models regression analysis begin look things happening using stored data begin answer questions based data alerts answer questions react actions needed now example sales executives receive alerts sales targets falling behind alerts learn problem notified something similar happens future alerts appear via e mail rss feeds red dials scorecard dashboard query drilldown or olap answers questions exactly problem find answers example sort explore data different types cell phone users calling behaviors query drilldown allows little bit discovery olap lets manipulate data find many color where ad hoc reports answer questions many often where example custom reports describe number hospital patients every diagnosis code day week best ad hoc reports let ask questions request couple custom reports find answers standard reports answer questions happened happen example monthly quarterly financial reports know these they re generated regular basis describe what happened particular area they re useful extent making long term decisions'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Keyword extraction","metadata":{}},{"cell_type":"markdown","source":"Keyword extraction is an important step in question answering systems because it helps the system understand the main topic and focus of the question. By identifying the keywords in a question, the system can use them to search for relevant information and retrieve the most relevant answer. Additionally, keyword extraction can also help to improve the efficiency of the question answering system by reducing the amount of irrelevant information that needs to be processed. Overall, keyword extraction helps to ensure that the system is able to understand and respond to the user's question accurately and efficiently.","metadata":{}},{"cell_type":"markdown","source":"## Topic Rank Algorithm","metadata":{}},{"cell_type":"markdown","source":"TopicRank is a keyword extraction algorithm that is based on graph-based ranking algorithms, such as PageRank. It works by creating a graph of words in a given text and then ranking the words based on their importance within the graph. The words with the highest rank are considered the most important or relevant keywords in the text. The algorithm takes into account the co-occurrence of words and the context in which they appear, and it can be used for a variety of natural language processing tasks, such as keyword extraction, text summarization, and document classification.","metadata":{}},{"cell_type":"code","source":"def topicRank(text):\n    # initialize keyphrase extraction model, here TopicRank\n    extractor = pke.unsupervised.TopicRank()\n\n    # load the content of the document, here document is expected to be in raw\n    # format (i.e. a simple text file) and preprocessing is carried out using spacy\n    extractor.load_document(input=text, language='en')\n\n    # keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n    # and adjectives (i.e. `(Noun|Adj)*`)\n    extractor.candidate_selection()\n\n    # candidate weighting, in the case of TopicRank: using a random walk algorithm\n    extractor.candidate_weighting()\n\n    # N-best selection, keyphrases contains the 10 highest scored candidates as\n    # (keyphrase, score) tuples\n    keyphrases = extractor.get_n_best(n=10)\n    return [a_tuple[0] for a_tuple in keyphrases]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:09.968481Z","iopub.execute_input":"2023-01-26T05:02:09.968852Z","iopub.status.idle":"2023-01-26T05:02:09.975805Z","shell.execute_reply.started":"2023-01-26T05:02:09.968819Z","shell.execute_reply":"2023-01-26T05:02:09.974630Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"keywords= []","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:10.119962Z","iopub.execute_input":"2023-01-26T05:02:10.120401Z","iopub.status.idle":"2023-01-26T05:02:10.125123Z","shell.execute_reply.started":"2023-01-26T05:02:10.120363Z","shell.execute_reply":"2023-01-26T05:02:10.124060Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for i in topicRank(context):\n    keywords.append(i)\ntopicRank(context)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:10.313647Z","iopub.execute_input":"2023-01-26T05:02:10.315372Z","iopub.status.idle":"2023-01-26T05:02:15.842178Z","shell.execute_reply.started":"2023-01-26T05:02:10.315333Z","shell.execute_reply":"2023-01-26T05:02:15.841001Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['question',\n 'example',\n 'alerts',\n 'data',\n 'vip customers',\n 'ad hoc reports',\n 'best decision',\n 'predictive modeling',\n 'answers',\n 'complex problem']"},"metadata":{}}]},{"cell_type":"markdown","source":"## TfIdf Algorithm","metadata":{}},{"cell_type":"markdown","source":"TF-IDF (term frequency-inverse document frequency) is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in information retrieval and text mining.\n\nThe TF part of the name represents the term frequency, which measures the number of times a term appears in a document. The IDF part represents the inverse document frequency, which measures the rarity of a term in the entire corpus.\n\nWhen used for keyword extraction, the algorithm first tokenizes the text and removes stopwords. It then calculates the TF-IDF score for each token. Tokens with the highest TF-IDF scores are considered as the keywords of the text.","metadata":{}},{"cell_type":"code","source":"def TfIdf(text):\n    # initialize keyphrase extraction model, here TfIdf\n    extractor = pke.unsupervised.TfIdf()\n\n    # load the content of the document, here document is expected to be in raw\n    # format (i.e. a simple text file) and preprocessing is carried out using spacy\n    extractor.load_document(input=text, language='en' )\n\n    # keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n    # and adjectives (i.e. `(Noun|Adj)*`)\n    extractor.candidate_selection()\n\n    # candidate weighting, in the case of TopicRank: using a random walk algorithm\n    extractor.candidate_weighting()\n\n    # N-best selection, keyphrases contains the 10 highest scored candidates as\n    # (keyphrase, score) tuples\n    keyphrases = extractor.get_n_best(n=10)\n    return [a_tuple[0] for a_tuple in keyphrases]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:15.844456Z","iopub.execute_input":"2023-01-26T05:02:15.844846Z","iopub.status.idle":"2023-01-26T05:02:15.852853Z","shell.execute_reply.started":"2023-01-26T05:02:15.844808Z","shell.execute_reply":"2023-01-26T05:02:15.851713Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for i in TfIdf(context):\n    keywords.append(i)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:15.854240Z","iopub.execute_input":"2023-01-26T05:02:15.854682Z","iopub.status.idle":"2023-01-26T05:02:19.700567Z","shell.execute_reply.started":"2023-01-26T05:02:15.854642Z","shell.execute_reply":"2023-01-26T05:02:19.699544Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"tfidfKeyWords = TfIdf(context)\nprint(tfidfKeyWords)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:19.703268Z","iopub.execute_input":"2023-01-26T05:02:19.703641Z","iopub.status.idle":"2023-01-26T05:02:23.221915Z","shell.execute_reply.started":"2023-01-26T05:02:19.703604Z","shell.execute_reply":"2023-01-26T05:02:23.220612Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"['alerts', 'answers', 'hottest', 'query drilldown', 'drilldown', 'olap', 'ad hoc reports', 'hoc reports', 'reports answer', 'forecasting']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Yake! (Yet Another Keyword Extractor)","metadata":{}},{"cell_type":"markdown","source":"Yake! is a simple yet effective unsupervised keyphrase extraction algorithm that is based on the intuition of the \"local\" keyword density distribution. It is language independent and it can be used to extract keywords in multiple languages. Yake! is based on the following two assumptions:\n\nWords that appear in the same context are likely to be semantically related\nWords that appear in the same context are likely to be important\nIt uses a combination of term frequency (TF) and inverse document frequency (IDF) to rank the keywords. The algorithm first splits the text into sentences, then into words, and finally into n-grams (e.g., bigrams, trigrams). It then calculates the TF-IDF for each n-gram and uses it to rank the keywords.\n\nin other words, YAKE first computes the term frequency-inverse document frequency (TF-IDF) for each token in the text, which is a measure of the importance of the token in the text. Then, it applies a K-Means algorithm on the TF-IDF vectors of the tokens to cluster the similar words together and find the centroids of the clusters. These centroids are considered as the keywords of the text.","metadata":{}},{"cell_type":"code","source":"def yake(text):\n    # initialize keyphrase extraction model, here YAKE\n    extractor = pke.unsupervised.YAKE()\n\n    # load the content of the document, here document is expected to be in raw\n    # format (i.e. a simple text file) and preprocessing is carried out using spacy\n    extractor.load_document(input=text, language='en')\n\n    # keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n    # and adjectives (i.e. `(Noun|Adj)*`)\n    extractor.candidate_selection()\n\n    # candidate weighting, in the case of TopicRank: using a random walk algorithm\n    extractor.candidate_weighting()\n\n    # N-best selection, keyphrases contains the 10 highest scored candidates as\n    # (keyphrase, score) tuples\n    keyphrases = extractor.get_n_best(n=10)\n    return [a_tuple[0] for a_tuple in keyphrases]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:23.224123Z","iopub.execute_input":"2023-01-26T05:02:23.224915Z","iopub.status.idle":"2023-01-26T05:02:23.231914Z","shell.execute_reply.started":"2023-01-26T05:02:23.224852Z","shell.execute_reply":"2023-01-26T05:02:23.230703Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for i in yake(context):\n    keywords.append(i)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:23.234185Z","iopub.execute_input":"2023-01-26T05:02:23.234924Z","iopub.status.idle":"2023-01-26T05:02:25.068580Z","shell.execute_reply.started":"2023-01-26T05:02:23.234851Z","shell.execute_reply":"2023-01-26T05:02:25.067490Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"yakeKeyWords = yake(context)\nprint(yakeKeyWords)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:25.069992Z","iopub.execute_input":"2023-01-26T05:02:25.070572Z","iopub.status.idle":"2023-01-26T05:02:26.893981Z","shell.execute_reply.started":"2023-01-26T05:02:25.070531Z","shell.execute_reply":"2023-01-26T05:02:26.892814Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"['example', 'questions', 'answers', 'reports', 'optimization', 'best', 'optimization answers', 'alerts', 'forecasting', 'predictive modeling']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## multipartiteRank","metadata":{}},{"cell_type":"code","source":"def multipartiteRank(text):\n    # initialize keyphrase extraction model, here TopicRank\n    extractor = pke.unsupervised.MultipartiteRank()\n\n    # load the content of the document, here document is expected to be in raw\n    # format (i.e. a simple text file) and preprocessing is carried out using spacy\n    extractor.load_document(input=text, language='en')\n\n    # keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n    # and adjectives (i.e. `(Noun|Adj)*`)\n    extractor.candidate_selection()\n\n    # candidate weighting, in the case of TopicRank: using a random walk algorithm\n    extractor.candidate_weighting()\n\n    # N-best selection, keyphrases contains the 10 highest scored candidates as\n    # (keyphrase, score) tuples\n    keyphrases = extractor.get_n_best(n=10)\n    return [a_tuple[0] for a_tuple in keyphrases]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:26.895525Z","iopub.execute_input":"2023-01-26T05:02:26.897148Z","iopub.status.idle":"2023-01-26T05:02:26.904782Z","shell.execute_reply.started":"2023-01-26T05:02:26.897104Z","shell.execute_reply":"2023-01-26T05:02:26.903634Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# for i in multipartiteRank(context):\n#     keywords.append(i)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T03:51:35.645794Z","iopub.execute_input":"2023-01-26T03:51:35.646163Z","iopub.status.idle":"2023-01-26T03:51:37.896838Z","shell.execute_reply.started":"2023-01-26T03:51:35.646130Z","shell.execute_reply":"2023-01-26T03:51:37.895793Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"multipartiteRankKeyWords = multipartiteRank(context)\nprint(multipartiteRankKeyWords)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:02:26.907856Z","iopub.execute_input":"2023-01-26T05:02:26.908380Z","iopub.status.idle":"2023-01-26T05:02:29.673929Z","shell.execute_reply.started":"2023-01-26T05:02:26.908341Z","shell.execute_reply":"2023-01-26T05:02:29.672788Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"['example', 'question', 'best decision', 'vip customers', 'complex problem', 'alerts', 'resource constraints', 'data', 'business priorities', 'predictive modeling']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"multipartiteRank keywords is the least one in importance and the important words in it are repeated in other algorithms used as Topic rank and TFIDF so, I will not add it to the list","metadata":{}},{"cell_type":"code","source":"d = dict(Counter(keywords))\nsorted_d = sorted(d.items(), key=lambda x: x[1], reverse = True)\npd.DataFrame(sorted_d,columns=['Word','Frequancy'])","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:09:08.926766Z","iopub.execute_input":"2023-01-26T05:09:08.927542Z","iopub.status.idle":"2023-01-26T05:09:08.940211Z","shell.execute_reply.started":"2023-01-26T05:09:08.927495Z","shell.execute_reply":"2023-01-26T05:09:08.939260Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                    Word  Frequancy\n0                 alerts          3\n1                answers          3\n2                example          2\n3         ad hoc reports          2\n4    predictive modeling          2\n5            forecasting          2\n6               question          1\n7                   data          1\n8          vip customers          1\n9          best decision          1\n10       complex problem          1\n11               hottest          1\n12       query drilldown          1\n13             drilldown          1\n14                  olap          1\n15           hoc reports          1\n16        reports answer          1\n17             questions          1\n18               reports          1\n19          optimization          1\n20                  best          1\n21  optimization answers          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Frequancy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>alerts</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>answers</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>example</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ad hoc reports</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>predictive modeling</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>forecasting</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>question</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>data</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>vip customers</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>best decision</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>complex problem</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>hottest</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>query drilldown</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>drilldown</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>olap</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>hoc reports</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>reports answer</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>questions</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>reports</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>optimization</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>best</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>optimization answers</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The keywords are good and we can use it in Question generation\n","metadata":{}},{"cell_type":"code","source":"#remove duplicated words\nkeywords = list(set(keywords))\n#get the number of keywords\nlen(keywords)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:10:12.332193Z","iopub.execute_input":"2023-01-26T05:10:12.332546Z","iopub.status.idle":"2023-01-26T05:10:12.340982Z","shell.execute_reply.started":"2023-01-26T05:10:12.332516Z","shell.execute_reply":"2023-01-26T05:10:12.340007Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"22"},"metadata":{}}]},{"cell_type":"markdown","source":"now we are able to generate 22 questions from the given article","metadata":{}},{"cell_type":"code","source":"# Write the list to a file\nwith open(\"keywords.txt\", \"w\") as f:\n    for line in keywords:\n        f.write(line + \"\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-01-26T05:12:33.572628Z","iopub.execute_input":"2023-01-26T05:12:33.573131Z","iopub.status.idle":"2023-01-26T05:12:33.583724Z","shell.execute_reply.started":"2023-01-26T05:12:33.573081Z","shell.execute_reply":"2023-01-26T05:12:33.582621Z"},"trusted":true},"execution_count":33,"outputs":[]}]}